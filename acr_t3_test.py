#!/usr/bin/env python3
"""
acr_t3_test.py
==============

Reads the .npz file generated by build_t3_counts.py and, for each radius sample, prints:

  - Analytical T3 test (Z and two-sided p-value)
  - If --cluster N is set: cluster-robust sigma with non-overlapping blocks of 50 trials (0 = off)
  - If --azuma     is set: append Azuma-Hoeffding two-sided tail-bound p-value
  - If --shuffle N is set: permutation p-value
  - If --bootstrap N is set: 95% CI for sigma via bootstrap

Shuffle modes
-------------
  pair  - shuffle entire pairs (A_i, B_i) between trials (breaks i <-> i+1)
  side  - shuffle only B, keeping A in place (the old "side" test)

All heavy computations are parallelized using --threads (default is 16).

The T3 and sigma formulas match those in build_t3_counts.py.
"""

from __future__ import annotations

import argparse, math, time
from pathlib import Path
from multiprocessing import Pool, cpu_count
from math import ceil, erfc, sqrt, exp

import numpy as np


# --------------------------------------------------------------------------- #
#  helpers                                                                    #
# --------------------------------------------------------------------------- #
def cluster_sigma(A: np.ndarray,
                  B: np.ndarray,
                  R: np.ndarray,
                  blocklen: int) -> float:
    """
    Cluster-robust (Newey-West/Andrews) standard error with
    **non-overlapping blocks** of length `blocklen`.

        y_i = 1_{ABR} - 1_{ABnR} - 1_{AnBR} - 1_{nABR}
              + 1_A + 1_B + 1_R

    We aggregate the *block sums*

        C_j = sum_{i in block j} y_i,

    j = 1...m,   m = ceil(N / blocklen),

    and set

        sigma^2_cluster  =  m * Var(C_j)

    (Using sums, not means, is the standard "sandwich" form; it
    automatically rescales for the block length.)
    """
    y = (
        (A & B & R).astype(int)
        - (A & B & ~R)
        - (A & ~B & R)
        - (~A & B & R)
        + A + B + R
    ).astype(int)

    N = len(y)
    m = ceil(N / blocklen)
    # pad to full blocks (last block may be shorter)
    pad = m * blocklen - N
    if pad:
        y = np.pad(y, (0, pad), constant_values=0)
    blocks = y.reshape(m, blocklen)

    # block sums
    block_sums = blocks.sum(axis=1)
    var_C = block_sums.var(ddof=1) if m > 1 else 0.0
    return float(sqrt(m * var_C))


def compute_t3_counts(A0: np.ndarray, B0: np.ndarray, R0: np.ndarray) -> tuple[dict, float]:
    """
    Given boolean arrays A_i, B_i (length N), constructs array R_i as
    events in trial i+1, then returns a dictionary of counts and sigma.
    The last trial is dropped (since there is no R_N).

    Returns: (counts_dict, Z) - Z is needed for shuffle to avoid recalculating it twice.
    """
    # A0,B0,R0 already have length N and the "shift" is done in build_t3_counts

    N = len(A0)

    N_A   = int(A0.sum())
    N_B   = int(B0.sum())
    N_C   = int(R0.sum())
    N_AB  = int(np.sum(A0 & B0 & ~R0))
    N_AC  = int(np.sum(A0 & ~B0 & R0))
    N_BC  = int(np.sum(~A0 & B0 & R0))
    N_ABC = int(np.sum(A0 & B0 & R0))

    # sigma: covariance formula for vector X (7 components)
    X = np.stack([
        A0 & B0 & R0,
        A0 & B0 & ~R0,
        A0 & ~B0 & R0,
        ~A0 & B0 & R0,
        A0, B0, R0
    ], axis=1).astype(int)

    coeff = np.array([1, -1, -1, -1, 1, 1, 1])
    cov   = np.cov(X, rowvar=False, bias=True)
    sigma = float(np.sqrt(N * coeff @ cov @ coeff)) if N > 0 else 0.0

    T3_raw = N_ABC - N_AB - N_AC - N_BC + N_A + N_B + N_C
    Z      = T3_raw / sigma if sigma > 0 else 0.0

    counts = dict(
        N_trials=N, N_A=N_A, N_B=N_B, N_C=N_C,
        N_AB=N_AB, N_AC=N_AC, N_BC=N_BC, N_ABC=N_ABC,
        sigma=sigma, Z=Z, T3=T3_raw
    )
    return counts, Z


# --------------------------------------------------------------------------- #
#  worker functions                                                           #
# --------------------------------------------------------------------------- #
def _shuffle_worker_pair(args):
    """
    Works in "pair" mode: shuffles entire pairs (A_i, B_i) between trials.
    """
    n_iter, seed, A, B, r_mode, Z_obs = args
    rng = np.random.default_rng(seed)
    N   = len(A)
    idx = np.arange(N)
    hits = 0

    for _ in range(n_iter):
        perm = rng.permutation(idx)
        # 1) rearrange A, B
        A_p = A[perm]
        B_p = B[perm]
        # 2) build new R_p from (A_p[i+1], B_p[i+1])
        # by shifting by 1. The last element = False
        R_p = np.empty_like(A_p, dtype=bool)
        if len(A_p) > 1:
            if r_mode == "any":
                R_p[:-1] = A_p[1:] | B_p[1:]
            elif r_mode == "alice":
                R_p[:-1] = A_p[1:]
            else: # "bob"
                R_p[:-1] = B_p[1:]
            R_p[-1] = False
        else:
            # edge case N=1
            R_p.fill(False)

        # 3) now compute T3
        _, Z_p = compute_t3_counts(A_p, B_p, R_p)
        if abs(Z_p) >= abs(Z_obs):
            hits += 1
    return hits


def _shuffle_worker_side(args):
    """
    Works in "side" mode: shuffles only B, keeping A in place.
    """
    n_iter, seed, A, B, r_mode, Z_obs = args
    rng = np.random.default_rng(seed)
    hits = 0

    for _ in range(n_iter):
        B_p = rng.permutation(B)
        # recalculate R based on (A, B_p)
        N = len(A)
        R_p = np.empty_like(A, dtype=bool)
        if N > 1:
            if r_mode == "any":
                R_p[:-1] = A[1:] | B_p[1:]
            elif r_mode == "alice":
                R_p[:-1] = A[1:]
            else: # "bob"
                R_p[:-1] = B_p[1:]
            R_p[-1] = False
        else:
            R_p.fill(False)

        _, Z_p = compute_t3_counts(A, B_p, R_p)
        if abs(Z_p) >= abs(Z_obs):
            hits += 1
    return hits


def _bootstrap_worker(args):
    """
    Each process takes n_iter, seed, A, B, r_mode and returns a list of sigma
    values for the M-th bootstrap.
    """
    n_iter, seed, A, B, r_mode = args
    rng     = np.random.default_rng(seed)
    N       = len(A)
    idx_all = np.arange(N)
    sigmas  = []

    for _ in range(n_iter):
        samp = rng.choice(idx_all, size=N, replace=True)
        # 1) A_b, B_b = samples with replacement
        A_b = A[samp]
        B_b = B[samp]
        # 2) R_b is recalculated from (A_b[i+1], B_b[i+1])
        R_b = np.empty_like(A_b, dtype=bool)
        if N > 1:
            if r_mode == "any":
                R_b[:-1] = A_b[1:] | B_b[1:]
            elif r_mode == "alice":
                R_b[:-1] = A_b[1:]
            else: # "bob"
                R_b[:-1] = B_b[1:]
            R_b[-1] = False
        else:
            R_b.fill(False)

        counts_b, _ = compute_t3_counts(A_b, B_b, R_b)
        sigmas.append(counts_b["sigma"])
    return sigmas


# --------------------------------------------------------------------------- #
#  formatted simple report                                                    #
# --------------------------------------------------------------------------- #
def analytic_report(tag: str,
                    counts: dict,
                    sigma_cl: float | None = None,
                    p_azuma : float | None = None) -> str:
    Z   = counts["Z"]
    p2  = 0.5 * erfc(abs(Z) / sqrt(2))
    rep = f"""
T3 TEST REPORT  -  {tag}
--------------------------------------
Trials (N-1)           = {counts['N_trials']}
T3 raw                 = {counts['T3']}
sigma (loc. realism)   = {counts['sigma']:.3f}
T3_norm (Z-score)      = {Z:.3f}
Analytic p-value (2-s) = {p2:.3g}"""

    if sigma_cl is not None and sigma_cl > 0:
        z_cl = counts['T3'] / sigma_cl if sigma_cl else float('nan')
        rep += f"""
sigma (cluster)        = {sigma_cl:.3f}
Z (cluster)            = {z_cl:.3f}"""
    if p_azuma is not None:
        rep += f"""
Azuma-Hoeffding p-val  = {p_azuma:.3g}"""

    rep += f"""
--------------------------------------
Counts:
    N_A   = {counts['N_A']}
    N_B   = {counts['N_B']}
    N_C   = {counts['N_C']}
    N_AB  = {counts['N_AB']}
    N_AC  = {counts['N_AC']}
    N_BC  = {counts['N_BC']}
    N_ABC = {counts['N_ABC']}
--------------------------------------"""
    return rep + "\n"


# --------------------------------------------------------------------------- #
#  main                                                                       #
# --------------------------------------------------------------------------- #
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--counts",      required=True, help=".npz от build_t3_counts.py")
    ap.add_argument("--name",        required=True, help="Run name (tag)")
    ap.add_argument("--shuffle",     type=int, default=0, help="Number of permutations for shuffle")
    ap.add_argument("--bootstrap",   type=int, default=0, help="Number of samples for bootstrap")
    ap.add_argument("--threads",     type=int, default=16, help="Number of parallel processes (default 16)")
    ap.add_argument("--cluster",     type=int, default=0, help="Block length for cluster-robust sigma (0 = off)")
    ap.add_argument("--azuma",       action="store_true", help="Also report Azuma-Hoeffding tail bound p-value")
    ap.add_argument("--shuffle-mode", choices=["pair", "side"], default="pair", help="'pair' or 'side' (default is 'pair')")
    ap.add_argument("--seed", type=int, default=None, help="RNG seed for shuffle / bootstrap (default: None)")
    args = ap.parse_args()

    # ---------------- load NPZ ----------------
    npz      = np.load(args.counts, allow_pickle=True)
    r_mode   = str(npz["mode"])
    radii    = npz["radii"]      # 1D float array
    # counts_a = npz["counts"]     # object array of dicts
    A_arr    = npz["A"]          # object array of boolean vectors
    B_arr    = npz["B"]
    R_arr    = npz["R"]

    max_workers = max(1, min(args.threads, cpu_count()))

    for idx, radius in enumerate(radii):
        A0 = A_arr[idx]
        B0 = B_arr[idx]
        R0 = R_arr[idx]
        # For safety, recalculate: counts are in NPZ, but it's more reliable to recompute
        counts_dict, Z_obs = compute_t3_counts(A0, B0, R0)

        # --- optional cluster-robust sigma --------------------------------
        sigma_cl = None
        if args.cluster > 0:
            sigma_cl = cluster_sigma(A0, B0, R0, args.cluster)

        # --- optional Azuma‑Hoeffding p-value -----------------------------
        p_azuma = None
        if args.azuma:
            # Each martingale increment y_i is in {0,1,4};  max|Delta y_i| = 4
            L = 4
            t = abs(counts_dict["T3"])
            n = counts_dict["N_trials"]
            p_azuma = 2 * exp(-t**2 / (2 * n * L * L))

        # 1) Analytical / extended report
        print(
            analytic_report(
                f"{args.name} (r={radius:.3f})",
                counts_dict,
                sigma_cl=sigma_cl,
                p_azuma=p_azuma
            )
        )

        # 2) Shuffle-test
        if args.shuffle > 0:
            base, rem = divmod(args.shuffle, max_workers)
            if args.seed is not None:
                print(f"Using seed {args.seed} for shuffle")
            ss     = np.random.SeedSequence(args.seed)
            seeds  = ss.spawn(max_workers)
            tasks  = []
            for w in range(max_workers):
                n_w = base + (1 if w < rem else 0)
                if n_w == 0:
                    continue
                if args.shuffle_mode == "pair":
                    tasks.append((n_w, seeds[w], A0, B0, r_mode, Z_obs))
                else:
                    tasks.append((n_w, seeds[w], A0, B0, r_mode, Z_obs))

            worker = _shuffle_worker_pair if args.shuffle_mode == "pair" else _shuffle_worker_side
            with Pool(max_workers) as pool:
                hits = sum(pool.map(worker, tasks))
            p_shuffle = (hits + 1) / (args.shuffle + 1)
            print(f"Shuffle (Mode={args.shuffle_mode}, N={args.shuffle}): p-value = {p_shuffle:.3e}\n")

        # 3) Bootstrap test
        if args.bootstrap > 0:
            base, rem = divmod(args.bootstrap, max_workers)
            if args.seed is not None:
                print(f"Using seed {args.seed} for bootstrap")
            ss     = np.random.SeedSequence(args.seed)
            seeds  = ss.spawn(max_workers)
            tasks  = [
                (base + (1 if w < rem else 0), seeds[w], A0, B0, r_mode)
                for w in range(max_workers) if base + (1 if w < rem else 0) > 0
            ]
            with Pool(max_workers) as pool:
                parts = pool.map(_bootstrap_worker, tasks)
            sigmas = np.concatenate(parts)
            lo, hi = np.percentile(sigmas, [2.5, 97.5])
            print(f"Bootstrap sigma 95 % CI  = [{lo:.3f}, {hi:.3f}]\n")

    # 4) Timestamp
    print(f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
